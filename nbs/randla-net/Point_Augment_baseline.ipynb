{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d320acfc-b25f-4e95-9015-c7513c83dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is trying to train Point Augment by averaging out the class labels obtained from a randla decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa0aefc-744e-4e42-8a8e-0248653b59ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from imps.data.scannet import ScanNetScene, CLASS_NAMES, MOVABLE_INSTANCE_NAMES\n",
    "from imps.sqn.model import Randla\n",
    "from imps.sqn.data_utils import prepare_input\n",
    "from imps.point_augment.Common import loss_utils, point_augment_utils\n",
    "\n",
    "from imps.point_augment.Common import loss_utils\n",
    "from imps.point_augment.Augmentor.augmentor import Augmentor\n",
    "\n",
    "SCENE_DIR = '/app/mnt/scans/scene0040_00'\n",
    "\n",
    "N_POINTS = int(1.5e5)\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "IGNORED_LABELS = [0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5e1ff0-2548-4b01-9703-51ebcedf886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = ScanNetScene(SCENE_DIR)\n",
    "surface_points, surface_colors, point_labels, point_instances, instance_number = scene.create_points_colors_labels_from_pc(N_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e74144-aec2-409c-968f-020f9b178a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = surface_points.mean(axis=0, keepdims=True)\n",
    "surface_points -= center\n",
    "    \n",
    "pts_min = surface_points.min(axis=0, keepdims=True)\n",
    "pts_max = surface_points.max(axis=0, keepdims=True)\n",
    "surface_points = (surface_points - pts_min) / (pts_max - pts_min)\n",
    "surface_points -= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc02e46e-ecfd-479e-8911-bdaf0eae00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg2idx = {c: i for i,c in enumerate(CLASS_NAMES)}\n",
    "movable_instances = dict((k, seg2idx[k]) for k in list(set(MOVABLE_INSTANCE_NAMES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fc7ab03-9385-430b-b9dd-6d7b319a705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unannotated': 0, 'wall': 1, 'floor': 2, 'cabinet': 3, 'bed': 4, 'chair': 5, 'sofa': 6, 'table': 7, 'door': 8, 'window': 9, 'bookshelf': 10, 'picture': 11, 'counter': 12, 'desk': 13, 'curtain': 14, 'refrigerator': 15, 'showercurtain': 16, 'toilet': 17, 'sink': 18, 'bathtub': 19, 'otherfurniture': 20}\n"
     ]
    }
   ],
   "source": [
    "print(seg2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3453b234-c88a-4c64-8b57-b1dae53905f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index_dict = {} \n",
    "for index, name in enumerate(list(seg2idx.keys())):\n",
    "    res_list = np.where(point_labels == index) # extracting indices corresponding to a label\n",
    "    label_index_dict[name] = res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4abb976-227c-4640-9c30-48090889f005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unannotated': (array([     3,      8,     10, ..., 149985, 149986, 149993]),), 'wall': (array([     2,      4,     12, ..., 149983, 149995, 149996]),), 'floor': (array([     6,      7,     14, ..., 149994, 149997, 149998]),), 'cabinet': (array([    24,     42,    132, ..., 149926, 149933, 149988]),), 'bed': (array([], dtype=int64),), 'chair': (array([   149,    202,    206, ..., 149929, 149967, 149984]),), 'sofa': (array([    16,    119,    166, ..., 149938, 149943, 149987]),), 'table': (array([   560,    806,    836, ..., 149757, 149935, 149966]),), 'door': (array([    34,     66,    136, ..., 149950, 149969, 149980]),), 'window': (array([    75,    112,    121, ..., 149527, 149885, 149888]),), 'bookshelf': (array([    11,     19,     23, ..., 149975, 149982, 149992]),), 'picture': (array([], dtype=int64),), 'counter': (array([], dtype=int64),), 'desk': (array([     0,      1,      5, ..., 149990, 149991, 149999]),), 'curtain': (array([], dtype=int64),), 'refrigerator': (array([], dtype=int64),), 'showercurtain': (array([], dtype=int64),), 'toilet': (array([], dtype=int64),), 'sink': (array([], dtype=int64),), 'bathtub': (array([], dtype=int64),), 'otherfurniture': (array([   114,    178,    196, ..., 149270, 149297, 149450]),)}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ce0d6b-5f52-4287-827d-d22aeaf95df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for calculation of randla_loss\n",
    "\n",
    "class_counts = []\n",
    "for c in range(len(CLASS_NAMES.keys())):\n",
    "    class_counts.append(np.sum(point_labels == c))\n",
    "class_counts = np.array(class_counts)\n",
    "\n",
    "for ign in IGNORED_LABELS:\n",
    "    class_counts[ign] = 0\n",
    "class_weights = class_counts / class_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15e0c67-0d4f-4e6f-a0c6-4625aa3134f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding out point_mask for now.\n",
    "\n",
    "def get_randla_loss(logits, labels, class_weights):\n",
    "    class_weights = torch.from_numpy(class_weights).float().to(logits.device)\n",
    "    logits = logits.reshape(-1, len(class_weights))\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='none')\n",
    "    output_loss = criterion(logits, labels)\n",
    "    \n",
    "   \n",
    "    n_points = output_loss.shape[0]\n",
    "        \n",
    "    output_loss = output_loss.sum() / n_points\n",
    "    \n",
    "    return output_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8edb6975-2ece-4389-8c91-63f60ce826f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_id_instances_list, original_instance_indices, instance_coordinates = point_augment_utils.get_instance_indices_dict(seg2idx, movable_instances, surface_points, point_labels, point_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d61efa2-3d50-40f8-8f63-264116de05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.FloatTensor(surface_colors).unsqueeze(0).to(DEVICE)\n",
    "xyz = torch.FloatTensor(surface_points).unsqueeze(0)\n",
    "point_labels = torch.LongTensor(point_labels).unsqueeze(0).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aab6427-0d85-499f-86bf-af615c1850a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing colors, surface_points and labels as tensors. Prepare the input for neural net operation. Initialize RandLA net\n",
    "\n",
    "input_points, input_neighbors, input_pools, feat_shape = prepare_input(xyz, k=16, num_layers=3, encoder_dims = [8,32,64], sub_sampling_ratio=4, \n",
    "                                                           device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab190972-ec6d-4719-b3ec-016fbc6af334",
   "metadata": {},
   "outputs": [],
   "source": [
    "randla = Randla(d_feature=3, d_in=8, encoder_dims=[8, 32, 64], device=DEVICE, num_class=len(CLASS_NAMES),interpolator='keops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fd66411-498b-4f37-9550-b2d3cf880bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize epoch, dimension, augmentor, optimizers\n",
    "dim = 3\n",
    "augmentor = Augmentor().cuda()\n",
    "optimizer_r = optim.Adam(randla.parameters(), lr=1e-3) # optimizer for randla \n",
    "optimizer_a = torch.optim.Adam(                        # optimzer for PA\n",
    "            augmentor.parameters(),\n",
    "            lr=0.001,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aaaf076-19e9-43eb-b5fe-3cefd9328ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = randla.forward(features, input_points, input_neighbors, input_pools) # had to change it for randla, was modified according to sqn\n",
    "output_label_dict = point_augment_utils.averaging_labels_from_randla_decoder(label_index_dict, logits, seg2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69b70aac-c80c-4ccf-b81e-8b13b038e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: tensor([ 1.1515,  0.8761,  1.0159,  0.0380,  0.4630,  1.2239,  0.5455,  0.2650,\n",
      "         0.0143,  0.1882,  0.6193,  0.0129,  0.3107,  0.1975,  0.5618,  0.4228,\n",
      "        -0.0173,  0.1909,  0.1468,  0.7037,  0.2597], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 1: tensor([ 1.0039,  0.8684,  1.0846, -0.0073,  0.4354,  1.0456,  0.5352,  0.2176,\n",
      "         0.1193,  0.2902,  0.5908, -0.0535,  0.3238,  0.1393,  0.4501,  0.2706,\n",
      "         0.0581,  0.2319,  0.1521,  0.7485,  0.3174], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 2: tensor([ 0.4962, -0.0302,  0.5091,  0.2253, -0.0712,  0.5387, -0.1200,  0.0889,\n",
      "        -0.0736, -0.1281,  0.0538,  0.1933,  0.4112,  0.0708,  0.6105,  0.0504,\n",
      "        -0.0090, -0.1212,  0.4091,  0.5621,  0.0886], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 3: tensor([ 1.2378,  0.4813,  1.2310,  0.0153,  0.2130,  1.0912,  0.2269,  0.0127,\n",
      "         0.0924,  0.0869,  0.3240, -0.0102,  0.2859, -0.0320,  0.5548, -0.0310,\n",
      "        -0.0225, -0.0611,  0.3809,  1.0191,  0.1300], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 4: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>), 5: tensor([ 0.4366,  0.1819,  0.1933,  0.1369,  0.1060,  0.5309,  0.1292,  0.1341,\n",
      "        -0.0622,  0.0589,  0.2212,  0.1767,  0.1745,  0.0911,  0.4103,  0.0937,\n",
      "        -0.0550,  0.1514,  0.2139,  0.3149,  0.1642], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 6: tensor([ 0.4778,  0.3517,  0.0869,  0.0324,  0.5464,  0.2315,  0.4454,  0.1366,\n",
      "         0.0296,  0.1925,  0.2997, -0.0322,  0.1183,  0.1694, -0.0249,  0.1175,\n",
      "         0.0601,  0.3484,  0.0977,  0.5332,  0.1685], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 7: tensor([ 1.5548,  2.9027,  1.2638, -0.2056,  1.5287,  1.0623,  1.8174,  0.7958,\n",
      "         0.5305,  0.6689,  1.6152, -0.2898,  0.8431,  0.9413, -0.1377,  1.4897,\n",
      "         0.6351,  0.4344, -0.3388,  0.5320,  0.6532], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 8: tensor([ 0.0547, -0.0732,  1.2681,  0.2994, -0.1606,  1.5668, -0.1369,  0.1127,\n",
      "        -0.2618, -0.4701, -0.0106,  0.2456, -0.0028, -0.2255,  2.2834,  0.4967,\n",
      "        -0.4269,  0.0144,  0.4242, -0.0079, -0.0639], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 9: tensor([ 3.0773,  4.2036,  1.7726, -0.3696,  2.2389,  2.1446,  1.9490,  1.4050,\n",
      "         0.1118,  0.2952,  2.8597, -0.5335,  1.6897,  1.7493, -0.2290,  1.4908,\n",
      "         0.6694,  0.6985, -0.4979,  1.6639,  1.2353], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 10: tensor([ 0.4097,  0.7538,  1.2050,  0.2863,  0.1594,  1.0938,  0.2330,  0.4374,\n",
      "        -0.0431, -0.0870,  0.4861, -0.0286,  0.5212,  0.0036,  1.1522,  0.5683,\n",
      "        -0.1535,  0.1675,  0.1017,  0.3147,  0.3535], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 11: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>), 12: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>), 13: tensor([ 0.8310,  0.8268,  0.6919,  0.0476,  0.6066,  0.9894,  0.6468,  0.2754,\n",
      "        -0.0411,  0.0927,  0.5628,  0.0576,  0.1700,  0.1426,  0.4307,  0.4306,\n",
      "        -0.0858,  0.3312,  0.1258,  0.4484,  0.1913], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>), 14: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>), 15: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>), 16: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>), 17: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>), 18: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>), 19: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>), 20: tensor([ 0.1494,  0.0835,  0.6820,  0.7872, -0.0852,  0.6127, -0.0359,  0.4186,\n",
      "        -0.1550, -0.2366, -0.0399,  0.5423,  0.6001, -0.0154,  1.2789,  0.6846,\n",
      "        -0.1133, -0.1409,  0.5979, -0.0033,  0.0256], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>)}\n"
     ]
    }
   ],
   "source": [
    "print(output_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6affde6-7ebf-48b8-ad01-1ffaf0c4f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Augmentor loss:4.2178, RandlaNet loss:0.4771, Epoch_duration: 1.83 s\n",
      "Epoch 2, Augmentor loss:3.7484, RandlaNet loss:0.4749, Epoch_duration: 1.81 s\n",
      "Epoch 3, Augmentor loss:3.2046, RandlaNet loss:0.4707, Epoch_duration: 1.8 s\n",
      "Epoch 4, Augmentor loss:2.5104, RandlaNet loss:0.4671, Epoch_duration: 1.78 s\n",
      "Epoch 5, Augmentor loss:2.18, RandlaNet loss:0.4634, Epoch_duration: 1.79 s\n",
      "Epoch 6, Augmentor loss:2.1126, RandlaNet loss:0.4604, Epoch_duration: 1.8 s\n",
      "Epoch 7, Augmentor loss:2.0858, RandlaNet loss:0.4559, Epoch_duration: 1.81 s\n",
      "Epoch 8, Augmentor loss:2.0582, RandlaNet loss:0.4518, Epoch_duration: 1.81 s\n",
      "Epoch 9, Augmentor loss:2.0287, RandlaNet loss:0.4477, Epoch_duration: 1.78 s\n",
      "Epoch 10, Augmentor loss:2.0063, RandlaNet loss:0.4445, Epoch_duration: 1.77 s\n",
      "Epoch 11, Augmentor loss:1.9966, RandlaNet loss:0.4416, Epoch_duration: 1.82 s\n",
      "Epoch 12, Augmentor loss:1.994, RandlaNet loss:0.439, Epoch_duration: 1.77 s\n",
      "Epoch 13, Augmentor loss:1.9845, RandlaNet loss:0.4363, Epoch_duration: 1.8 s\n",
      "Epoch 14, Augmentor loss:1.9891, RandlaNet loss:0.4338, Epoch_duration: 1.79 s\n",
      "Epoch 15, Augmentor loss:1.9675, RandlaNet loss:0.4308, Epoch_duration: 1.81 s\n",
      "Epoch 16, Augmentor loss:1.9594, RandlaNet loss:0.4279, Epoch_duration: 1.79 s\n",
      "Epoch 17, Augmentor loss:1.9682, RandlaNet loss:0.4252, Epoch_duration: 1.78 s\n",
      "Epoch 18, Augmentor loss:1.9654, RandlaNet loss:0.422, Epoch_duration: 1.79 s\n",
      "Epoch 19, Augmentor loss:1.9619, RandlaNet loss:0.4186, Epoch_duration: 1.8 s\n",
      "Epoch 20, Augmentor loss:1.9639, RandlaNet loss:0.4152, Epoch_duration: 1.78 s\n",
      "Epoch 21, Augmentor loss:1.9629, RandlaNet loss:0.4115, Epoch_duration: 1.82 s\n",
      "Epoch 22, Augmentor loss:1.9545, RandlaNet loss:0.4076, Epoch_duration: 1.81 s\n",
      "Epoch 23, Augmentor loss:1.9556, RandlaNet loss:0.4038, Epoch_duration: 1.82 s\n",
      "Epoch 24, Augmentor loss:1.9391, RandlaNet loss:0.3997, Epoch_duration: 1.79 s\n",
      "Epoch 25, Augmentor loss:1.931, RandlaNet loss:0.3957, Epoch_duration: 1.79 s\n",
      "Epoch 26, Augmentor loss:1.9265, RandlaNet loss:0.3917, Epoch_duration: 1.79 s\n",
      "Epoch 27, Augmentor loss:1.9805, RandlaNet loss:0.3879, Epoch_duration: 1.79 s\n",
      "Epoch 28, Augmentor loss:1.989, RandlaNet loss:0.3846, Epoch_duration: 1.78 s\n",
      "Epoch 29, Augmentor loss:1.9761, RandlaNet loss:0.3816, Epoch_duration: 1.78 s\n",
      "Epoch 30, Augmentor loss:1.9597, RandlaNet loss:0.379, Epoch_duration: 1.79 s\n",
      "Epoch 31, Augmentor loss:1.9514, RandlaNet loss:0.3766, Epoch_duration: 1.79 s\n",
      "Epoch 32, Augmentor loss:1.9509, RandlaNet loss:0.3741, Epoch_duration: 1.85 s\n",
      "Epoch 33, Augmentor loss:1.9703, RandlaNet loss:0.3717, Epoch_duration: 1.79 s\n",
      "Epoch 34, Augmentor loss:1.9696, RandlaNet loss:0.3687, Epoch_duration: 1.8 s\n",
      "Epoch 35, Augmentor loss:1.9529, RandlaNet loss:0.3653, Epoch_duration: 1.78 s\n",
      "Epoch 36, Augmentor loss:1.9368, RandlaNet loss:0.3621, Epoch_duration: 1.8 s\n",
      "Epoch 37, Augmentor loss:1.9215, RandlaNet loss:0.3589, Epoch_duration: 1.8 s\n",
      "Epoch 38, Augmentor loss:1.9613, RandlaNet loss:0.3557, Epoch_duration: 1.79 s\n",
      "Epoch 39, Augmentor loss:1.9762, RandlaNet loss:0.3531, Epoch_duration: 1.8 s\n",
      "Epoch 40, Augmentor loss:1.9773, RandlaNet loss:0.351, Epoch_duration: 1.78 s\n",
      "Epoch 41, Augmentor loss:1.9654, RandlaNet loss:0.3491, Epoch_duration: 1.78 s\n",
      "Epoch 42, Augmentor loss:1.9507, RandlaNet loss:0.3476, Epoch_duration: 1.89 s\n",
      "Epoch 43, Augmentor loss:1.943, RandlaNet loss:0.3461, Epoch_duration: 1.78 s\n",
      "Epoch 44, Augmentor loss:1.9365, RandlaNet loss:0.3447, Epoch_duration: 1.8 s\n",
      "Epoch 45, Augmentor loss:1.9439, RandlaNet loss:0.3431, Epoch_duration: 1.77 s\n",
      "Epoch 46, Augmentor loss:1.9487, RandlaNet loss:0.3413, Epoch_duration: 1.78 s\n",
      "Epoch 47, Augmentor loss:1.941, RandlaNet loss:0.3393, Epoch_duration: 1.79 s\n",
      "Epoch 48, Augmentor loss:1.945, RandlaNet loss:0.3373, Epoch_duration: 1.79 s\n",
      "Epoch 49, Augmentor loss:1.9395, RandlaNet loss:0.3352, Epoch_duration: 1.83 s\n",
      "Epoch 50, Augmentor loss:1.9234, RandlaNet loss:0.3331, Epoch_duration: 1.8 s\n",
      "Epoch 51, Augmentor loss:1.9213, RandlaNet loss:0.331, Epoch_duration: 1.83 s\n",
      "Epoch 52, Augmentor loss:1.9566, RandlaNet loss:0.3291, Epoch_duration: 1.8 s\n",
      "Epoch 53, Augmentor loss:1.9231, RandlaNet loss:0.3271, Epoch_duration: 1.82 s\n",
      "Epoch 54, Augmentor loss:1.9504, RandlaNet loss:0.3255, Epoch_duration: 1.8 s\n",
      "Epoch 55, Augmentor loss:1.9548, RandlaNet loss:0.3239, Epoch_duration: 1.79 s\n",
      "Epoch 56, Augmentor loss:1.9166, RandlaNet loss:0.3223, Epoch_duration: 1.82 s\n",
      "Epoch 57, Augmentor loss:1.9437, RandlaNet loss:0.3209, Epoch_duration: 1.84 s\n",
      "Epoch 58, Augmentor loss:1.9226, RandlaNet loss:0.3194, Epoch_duration: 1.79 s\n",
      "Epoch 59, Augmentor loss:1.9407, RandlaNet loss:0.3178, Epoch_duration: 1.8 s\n",
      "Epoch 60, Augmentor loss:1.9268, RandlaNet loss:0.3162, Epoch_duration: 1.88 s\n",
      "Epoch 61, Augmentor loss:1.9344, RandlaNet loss:0.3142, Epoch_duration: 1.79 s\n",
      "Epoch 62, Augmentor loss:1.9407, RandlaNet loss:0.3122, Epoch_duration: 1.79 s\n",
      "Epoch 63, Augmentor loss:1.9169, RandlaNet loss:0.3104, Epoch_duration: 1.87 s\n",
      "Epoch 64, Augmentor loss:1.9116, RandlaNet loss:0.3084, Epoch_duration: 1.8 s\n",
      "Epoch 65, Augmentor loss:1.9067, RandlaNet loss:0.3063, Epoch_duration: 1.8 s\n",
      "Epoch 66, Augmentor loss:1.9061, RandlaNet loss:0.3042, Epoch_duration: 1.79 s\n",
      "Epoch 67, Augmentor loss:1.9069, RandlaNet loss:0.3023, Epoch_duration: 1.83 s\n",
      "Epoch 68, Augmentor loss:1.9052, RandlaNet loss:0.3005, Epoch_duration: 1.78 s\n",
      "Epoch 69, Augmentor loss:1.9786, RandlaNet loss:0.2987, Epoch_duration: 1.79 s\n",
      "Epoch 70, Augmentor loss:1.897, RandlaNet loss:0.2977, Epoch_duration: 1.8 s\n",
      "Epoch 71, Augmentor loss:1.9492, RandlaNet loss:0.2961, Epoch_duration: 1.79 s\n",
      "Epoch 72, Augmentor loss:1.9055, RandlaNet loss:0.2957, Epoch_duration: 1.79 s\n",
      "Epoch 73, Augmentor loss:1.9411, RandlaNet loss:0.2939, Epoch_duration: 1.83 s\n",
      "Epoch 74, Augmentor loss:1.9295, RandlaNet loss:0.2935, Epoch_duration: 1.81 s\n",
      "Epoch 75, Augmentor loss:1.9377, RandlaNet loss:0.2912, Epoch_duration: 1.78 s\n",
      "Epoch 76, Augmentor loss:1.9281, RandlaNet loss:0.2903, Epoch_duration: 1.78 s\n",
      "Epoch 77, Augmentor loss:1.9149, RandlaNet loss:0.2883, Epoch_duration: 1.79 s\n",
      "Epoch 78, Augmentor loss:1.9536, RandlaNet loss:0.2853, Epoch_duration: 1.79 s\n",
      "Epoch 79, Augmentor loss:1.9636, RandlaNet loss:0.2834, Epoch_duration: 1.79 s\n",
      "Epoch 80, Augmentor loss:1.8944, RandlaNet loss:0.2826, Epoch_duration: 1.8 s\n",
      "Epoch 81, Augmentor loss:1.9476, RandlaNet loss:0.2804, Epoch_duration: 1.8 s\n",
      "Epoch 82, Augmentor loss:1.9548, RandlaNet loss:0.279, Epoch_duration: 1.87 s\n",
      "Epoch 83, Augmentor loss:1.931, RandlaNet loss:0.2781, Epoch_duration: 1.79 s\n",
      "Epoch 84, Augmentor loss:1.9362, RandlaNet loss:0.2771, Epoch_duration: 1.79 s\n",
      "Epoch 85, Augmentor loss:1.9368, RandlaNet loss:0.2762, Epoch_duration: 1.81 s\n",
      "Epoch 86, Augmentor loss:1.9384, RandlaNet loss:0.2754, Epoch_duration: 1.78 s\n",
      "Epoch 87, Augmentor loss:1.9431, RandlaNet loss:0.274, Epoch_duration: 1.79 s\n",
      "Epoch 88, Augmentor loss:1.9627, RandlaNet loss:0.2733, Epoch_duration: 1.82 s\n",
      "Epoch 89, Augmentor loss:1.9359, RandlaNet loss:0.2711, Epoch_duration: 1.81 s\n",
      "Epoch 90, Augmentor loss:1.908, RandlaNet loss:0.2689, Epoch_duration: 1.82 s\n",
      "Epoch 91, Augmentor loss:1.9477, RandlaNet loss:0.2663, Epoch_duration: 1.79 s\n",
      "Epoch 92, Augmentor loss:1.9025, RandlaNet loss:0.2651, Epoch_duration: 1.8 s\n",
      "Epoch 93, Augmentor loss:1.9078, RandlaNet loss:0.2637, Epoch_duration: 1.79 s\n",
      "Epoch 94, Augmentor loss:1.9138, RandlaNet loss:0.2624, Epoch_duration: 1.82 s\n",
      "Epoch 95, Augmentor loss:1.9027, RandlaNet loss:0.2614, Epoch_duration: 1.79 s\n",
      "Epoch 96, Augmentor loss:1.9912, RandlaNet loss:0.2599, Epoch_duration: 1.79 s\n",
      "Epoch 97, Augmentor loss:1.8926, RandlaNet loss:0.2598, Epoch_duration: 1.8 s\n",
      "Epoch 98, Augmentor loss:1.9284, RandlaNet loss:0.2587, Epoch_duration: 1.81 s\n",
      "Epoch 99, Augmentor loss:1.9228, RandlaNet loss:0.2591, Epoch_duration: 1.78 s\n",
      "Epoch 100, Augmentor loss:1.9311, RandlaNet loss:0.2583, Epoch_duration: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "randla.train()\n",
    "augmentor=augmentor.train()\n",
    "\n",
    "for epoch in range(0, 100):  \n",
    "    # Original Point Cloud operation: \n",
    "    start_step1 = time.time()\n",
    "    \n",
    "    logits = randla.forward(features, input_points, input_neighbors, input_pools) # had to change it for randla, was modified according to sqn\n",
    "    output_label_dict = averaging_labels_from_randla_decoder(label_index_dict, logits, len_instances = len(CLASS_NAMES))\n",
    "    table_logits = output_label_dict[7]\n",
    "\n",
    "    \n",
    "    \n",
    "    # Noise variable added to generate feature matrix \n",
    "    optimizer_a.zero_grad()\n",
    "    optimizer_r.zero_grad()\n",
    "    for key,value in instance_coordinates.items():\n",
    "        for index, coord in enumerate(value):\n",
    "            coord = torch.FloatTensor(coord).unsqueeze(0).to(DEVICE)\n",
    "            coord=coord.transpose(2,1).contiguous()\n",
    "            noise = 0.02 * torch.randn(1, 1024).cuda()\n",
    "            aug_instance = augmentor(coord, noise)\n",
    "            augmented_scene = point_augment_utils.add_aug_instance_to_pc(aug_instance, surface_points, original_instance_indices[key][index])\n",
    "\n",
    "    augmented_scene = torch.FloatTensor(augmented_scene).unsqueeze(0)\n",
    "    \n",
    "    # Augmented Point Cloud Operation:\n",
    "    \n",
    "    # DOUBT:# I have to do this. As augmented point cloud is generated during each epoch and I need to prepare input for it. Any solution?\n",
    "    input_points_aug, input_neighbors_aug, input_pools_aug, feat_shape = prepare_input(augmented_scene, k=16, num_layers=3, sub_sampling_ratio=4, \n",
    "                                                           device=DEVICE)  \n",
    "\n",
    "\n",
    "\n",
    "    logits_aug = randla.forward(features, input_points_aug, input_neighbors_aug, input_pools_aug)\n",
    "    output_label_dict_aug = averaging_labels_from_randla_decoder(label_index_dict, logits_aug, len_instances = len(CLASS_NAMES))\n",
    "    aug_table_logits = output_label_dict_aug[7] # calculate the logits for the augmented table\n",
    "\n",
    "  \n",
    "    \n",
    "                     \n",
    "    augLoss  = loss_utils.aug_loss(table_logits.unsqueeze(0), aug_table_logits.unsqueeze(0))  \n",
    "    randlaLoss = get_randla_loss(logits_aug, point_labels, class_weights) #how do I calculate randla_loss here? Do I calculate loss between logits_augmented and logits true?\n",
    "\n",
    "\n",
    "    augLoss.backward(retain_graph=True)\n",
    "    randlaLoss.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "    optimizer_r.step()\n",
    "    optimizer_a.step()\n",
    "    start_step2 = time.time()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Augmentor loss:{round(augLoss.item(), 4)}, RandlaNet loss:{round(randlaLoss.item(), 4)}, Epoch_duration: {round((start_step2-start_step1),2)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fbdf00b-21df-4573-a880-f955c58e7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(randla.state_dict(), '../../processed/saved_models/PA_baseline_scene0040_00')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
