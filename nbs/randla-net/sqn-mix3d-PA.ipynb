{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5536c78-76cc-4617-b7f0-64f602bdd115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imps.data.scannet import ScanNetScene, CLASS_NAMES\n",
    "from imps.sqn.model import SQN\n",
    "from imps.sqn.data_utils import prepare_input\n",
    "from imps.point_augment.Augmentor.augmentor import Augmentor\n",
    "import imps.point_augment.Common.data_utils as d_utils\n",
    "\n",
    "from random import choice\n",
    "from random import random, sample, uniform\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "import volumentations as V\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import scipy\n",
    "\n",
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1daa3176-98b3-4ee6-9c65-3ff9050fdf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_DIR1 = '/app/mnt/scans/scene0040_00'\n",
    "SCENE_DIR2 = '/app/mnt/scans/scene0041_00'\n",
    "SCENE_DIR3 = '/app/mnt/scans/scene0009_00'\n",
    "SCENE_DIR4 = '/app/mnt/scans/scene0025_00'\n",
    "\n",
    "image_augmentations_path = \"/app/configs/albumentations_aug.yaml\"\n",
    "volume_augmentations_path = \"/app/configs/volumentations_aug.yaml\"\n",
    "color_mean_std = \"/app/processed/color_mean_std.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "411a1be1-16af-4c16-a642-782c68e3afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_POINTS = int(1.5e5)\n",
    "# Not important we are not using this here yet. Keep this small for quick data processing\n",
    "RESOLUTION = 25\n",
    "SIGMAS = None\n",
    "LABEL_RATIO = 1\n",
    "N_LABEL = int(N_POINTS*LABEL_RATIO)\n",
    "DEVICE = 'cuda'\n",
    "IGNORED_LABELS = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b669c25-44be-445c-8c96-2119ceea94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(logits, labels, class_weights):\n",
    "    class_weights = torch.from_numpy(class_weights).float().to(logits.device)\n",
    "    logits = logits.reshape(-1, len(class_weights))\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='none')\n",
    "    output_loss = criterion(logits, labels)\n",
    "    output_loss = output_loss.mean()\n",
    "    \n",
    "    return output_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08185daa-aaa5-4cef-8d7f-513fa83324c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_yaml(filepath):\n",
    "    with open(filepath) as f:\n",
    "        file = yaml.safe_load(f)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d5cb1-c105-4268-a6dc-f6169c0b27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_in_center(coordinates):\n",
    "    # moving coordinates to center\n",
    "    coordinates -= coordinates.mean(0)\n",
    "    aug = V.Compose(\n",
    "        [\n",
    "            V.Flip3d(axis=(0, 1, 0), always_apply=True),\n",
    "            V.Flip3d(axis=(1, 0, 0), always_apply=True),\n",
    "        ]\n",
    "    )\n",
    "    first_crop = coordinates[:, 0] > 0\n",
    "    first_crop &= coordinates[:, 1] > 0\n",
    "    # x -y\n",
    "    second_crop = coordinates[:, 0] > 0\n",
    "    second_crop &= coordinates[:, 1] < 0\n",
    "    # -x y\n",
    "    third_crop = coordinates[:, 0] < 0\n",
    "    third_crop &= coordinates[:, 1] > 0\n",
    "    # -x -y\n",
    "    fourth_crop = coordinates[:, 0] < 0\n",
    "    fourth_crop &= coordinates[:, 1] < 0\n",
    "\n",
    "    if first_crop.size > 1:\n",
    "        coordinates[first_crop] = aug(points=coordinates[first_crop])[\"points\"]\n",
    "    if second_crop.size > 1:\n",
    "        minimum = coordinates[second_crop].min(0)\n",
    "        minimum[2] = 0\n",
    "        minimum[0] = 0\n",
    "        coordinates[second_crop] = aug(points=coordinates[second_crop])[\"points\"]\n",
    "        coordinates[second_crop] += minimum\n",
    "    if third_crop.size > 1:\n",
    "        minimum = coordinates[third_crop].min(0)\n",
    "        minimum[2] = 0\n",
    "        minimum[1] = 0\n",
    "        coordinates[third_crop] = aug(points=coordinates[third_crop])[\"points\"]\n",
    "        coordinates[third_crop] += minimum\n",
    "    if fourth_crop.size > 1:\n",
    "        minimum = coordinates[fourth_crop].min(0)\n",
    "        minimum[2] = 0\n",
    "        coordinates[fourth_crop] = aug(points=coordinates[fourth_crop])[\"points\"]\n",
    "        coordinates[fourth_crop] += minimum\n",
    "\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade6e7d-c1c8-4ec0-bb57-82cf797e6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_distortion(pointcloud, granularity, magnitude):\n",
    "    \"\"\"Apply elastic distortion on sparse coordinate space.\n",
    "\n",
    "    pointcloud: numpy array of (number of points, at least 3 spatial dims)\n",
    "    granularity: size of the noise grid (in same scale[m/cm] as the voxel grid)\n",
    "    magnitude: noise multiplier\n",
    "  \"\"\"\n",
    "    blurx = np.ones((3, 1, 1, 1)).astype(\"float32\") / 3\n",
    "    blury = np.ones((1, 3, 1, 1)).astype(\"float32\") / 3\n",
    "    blurz = np.ones((1, 1, 3, 1)).astype(\"float32\") / 3\n",
    "    coords = pointcloud[:, :3]\n",
    "    coords_min = coords.min(0)\n",
    "\n",
    "    # Create Gaussian noise tensor of the size given by granularity.\n",
    "    noise_dim = ((coords - coords_min).max(0) // granularity).astype(int) + 3\n",
    "    noise = np.random.randn(*noise_dim, 3).astype(np.float32)\n",
    "\n",
    "    # Smoothing.\n",
    "    for _ in range(2):\n",
    "        noise = scipy.ndimage.filters.convolve(noise, blurx, mode=\"constant\", cval=0)\n",
    "        noise = scipy.ndimage.filters.convolve(noise, blury, mode=\"constant\", cval=0)\n",
    "        noise = scipy.ndimage.filters.convolve(noise, blurz, mode=\"constant\", cval=0)\n",
    "\n",
    "    # Trilinear interpolate noise filters for each spatial dimensions.\n",
    "    ax = [\n",
    "        np.linspace(d_min, d_max, d)\n",
    "        for d_min, d_max, d in zip(\n",
    "            coords_min - granularity,\n",
    "            coords_min + granularity * (noise_dim - 2),\n",
    "            noise_dim,\n",
    "        )\n",
    "    ]\n",
    "    interp = scipy.interpolate.RegularGridInterpolator(\n",
    "        ax, noise, bounds_error=0, fill_value=0\n",
    "    )\n",
    "    pointcloud[:, :3] = coords + interp(coords) * magnitude\n",
    "    return pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3532c1f-b007-448b-81ce-eadbdcd3e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_idxs = np.random.choice(N_POINTS, N_LABEL, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e65883db-5a35-43dd-a0c1-cbd15eedfd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(1,51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b310940-9655-4675-a98c-2f692c29b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene1 = ScanNetScene(SCENE_DIR1)\n",
    "\n",
    "voxel_grid1, surface_points1, surface_colors1, vicinity_points1, vicinity_distances1, point_labels1 = scene1.create_if_data(\n",
    "    RESOLUTION, N_POINTS, SIGMAS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f25369fa-c7d2-4da5-8492-81b51e48b764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  2  0 ... 10  1  0]\n",
      "(150000,)\n"
     ]
    }
   ],
   "source": [
    "#scene 1\n",
    "\n",
    "class_counts1 = []\n",
    "for c in range(len(CLASS_NAMES.keys())):\n",
    "    class_counts1.append(np.sum(point_labels1 == c))\n",
    "class_counts1 = np.array(class_counts1)\n",
    "\n",
    "for ign in IGNORED_LABELS:\n",
    "    class_counts1[ign] = 0\n",
    "class_weights1 = class_counts1 / class_counts1.sum()\n",
    "\n",
    "\n",
    "query_points1 = surface_points1[query_idxs]\n",
    "query_labels1 = point_labels1[query_idxs]\n",
    "print(query_labels1)\n",
    "print(query_labels1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1799103-d24c-4417-b0f1-71f573479551",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_dim = 3\n",
    "augmentor = Augmentor().cuda()\n",
    "optimizer_a = optim.Adam(\n",
    "            augmentor.parameters(),\n",
    "            lr=0.001,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            weight_decay=0.0001\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8928153-42cc-4221-99d4-9fd9fe918ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single scene\n",
    "\n",
    "features1 = torch.FloatTensor(surface_colors1).unsqueeze(0).to(DEVICE)\n",
    "xyz1 = torch.FloatTensor(surface_points1).unsqueeze(0)\n",
    "query1 = torch.FloatTensor(query_points1).unsqueeze(0).to(DEVICE)\n",
    "query_labels1 = torch.LongTensor(query_labels1).unsqueeze(0).to(DEVICE)\n",
    "#input_points1, input_neighbors1, input_pools1 = prepare_input(xyz1, k=16, num_layers=3, sub_sampling_ratio=4, \n",
    "                                             #              device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e170ae1d-3738-4ef8-bd6a-a8f4e0b4733f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sqn1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0c62d2c9bf5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#sqn1 = SQN(d_feature=3, d_in=8, encoder_dims=[8, 32, 64], len_class= len(CLASS_NAMES), decoder_dims=[64, len(CLASS_NAMES)], device=DEVICE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer1_sqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sqn1' is not defined"
     ]
    }
   ],
   "source": [
    "#sqn1 = SQN(d_feature=3, d_in=8, encoder_dims=[8, 32, 64], len_class= len(CLASS_NAMES), decoder_dims=[64, len(CLASS_NAMES)], device=DEVICE)\n",
    "optimizer1_sqn = optim.Adam(sqn1.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d148810-4c41-4f62-b2d2-8bdd4545a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_loss(pred, pred_aug, query_labels, class_weights):\n",
    "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
    "    mse_fn = torch.nn.MSELoss(reduce=True, size_average=True)\n",
    "    \n",
    "    loss = get_loss(pred, query_labels, class_weights)\n",
    "    loss_aug = get_loss(pred_aug, query_labels, class_weights)\n",
    "    \n",
    "    pc_con = F.softmax(pred, dim=-1)#.max(dim=1)[0]\n",
    "    one_hot = F.one_hot(gold, pred.shape[1]).float()\n",
    "    pc_con = (pc_con*one_hot).max(dim=1)[0]    \n",
    "    parameters = torch.max(torch.tensor(NUM).cuda(), torch.exp(pc_con) * NUM).cuda()\n",
    "    \n",
    "    # both losses are usable\n",
    "    aug_diff = 1.0 * torch.abs(1.0 - torch.exp(loss_aug - loss * parameters)).mean()\n",
    "    #aug_diff =  W*torch.abs(cls_aug_raw - cls_pc_raw*parameters).mean()\n",
    "    aug_loss = loss_aug + aug_diff\n",
    "\n",
    "    return aug_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cd446a6-b080-4324-90f7-e7f96ffc6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_loss(pred, pred_aug, pc_feat, aug_feat):\n",
    "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
    "    mse_fn = torch.nn.MSELoss(reduce=True, size_average=True)\n",
    "\n",
    "    loss = get_loss(pred, query_labels, class_weights)\n",
    "    loss_aug = get_loss(pred_aug, query_labels, class_weights)\n",
    "    \n",
    "    feat_diff = 10.0*mse_fn(pc_feat,aug_feat)\n",
    "    parameters = torch.max(torch.tensor(NUM).cuda(), torch.exp(1.0-loss)**2).cuda()\n",
    "    \n",
    "    cls_diff = (torch.abs(loss - loss_aug) * (parameters*2)).mean()\n",
    "    cls_loss = loss + loss_aug  + feat_diff# + cls_diff\n",
    "\n",
    "    return cls_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7855516f-c4a4-4560-9fc6-5f641ce11ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skip_connections is True and decoder_dims is given. Will not take decoder_dims into account\n"
     ]
    }
   ],
   "source": [
    "PointcloudScaleAndTranslate = d_utils.PointcloudScaleAndTranslate() #initiate augmentation\n",
    "sqn1 = SQN(d_feature=3, d_in=8, encoder_dims=[8, 32, 64], len_class= len(CLASS_NAMES), decoder_dims=[64, len(CLASS_NAMES)], device=DEVICE)\n",
    "optimizer1_sqn = optim.Adam(sqn1.parameters(), lr=1e-3)\n",
    "loss_list1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14138da0-ab47-405f-b42d-2140ef42befa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0626, -0.0578, -0.0221],\n",
      "        [-0.4710, -0.0841,  0.0873],\n",
      "        [ 0.2765,  0.2337, -0.1998],\n",
      "        ...,\n",
      "        [-0.2421,  0.4181,  0.1388],\n",
      "        [-0.1444,  0.3924,  0.1471],\n",
      "        [-0.3464,  0.3534, -0.0728]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-697be3f37fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxyz1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msurface_points_augmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointcloudScaleAndTranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcuda_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurface_points_augmented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mget_cuda_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurface_points_augmented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/src/imps/point_augment/Common/data_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pc)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m#print(xyz1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mxyz2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m#xyz1 = torch.from_numpy(xyz1).float().cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "xyz1=xyz1.to(DEVICE)\n",
    "surface_points_augmented = PointcloudScaleAndTranslate(xyz1).to(DEVICE)\n",
    "cuda_check = surface_points_augmented.is_cuda\n",
    "if cuda_check:\n",
    "    get_cuda_device = surface_points_augmented.get_device()\n",
    "    \n",
    "print(get_cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5185b70b-397c-4fe4-aeb3-c9b33a607dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0626, -0.0578, -0.0221],\n",
      "         [-0.4710, -0.0841,  0.0873],\n",
      "         [ 0.2765,  0.2337, -0.1998],\n",
      "         ...,\n",
      "         [-0.2421,  0.4181,  0.1388],\n",
      "         [-0.1444,  0.3924,  0.1471],\n",
      "         [-0.3464,  0.3534, -0.0728]]])\n"
     ]
    }
   ],
   "source": [
    "print(xyz1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b56ec102-b412-4ea8-98c0-58c4ebd880ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz1=xyz1.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94183c6a-a3bb-4c1b-98b1-1035c4be5c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2951,  0.2427, -0.0070],\n",
      "        [-0.3027,  0.3994, -0.0803],\n",
      "        [ 0.1859,  0.2980, -0.0850],\n",
      "        ...,\n",
      "        [-0.1559,  0.3550,  0.0449],\n",
      "        [ 0.1637, -0.3562, -0.1952],\n",
      "        [-0.3131,  0.3978,  0.1608]], device='cuda:0')\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 512])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-17e1d90a1ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer1_sqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0maug_pc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmentor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurface_points_augmented\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# obtaining the augmented point cloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# SQN without augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     input_points1, input_neighbors1, input_pools1 = prepare_input(surface_points_augmented, k=16, num_layers=3, sub_sampling_ratio=4, \n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/src/imps/point_augment/Augmentor/augmentor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pt, noise)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mfeat_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mfeat_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_r\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mrotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mfeat_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/src/imps/point_augment/Augmentor/augmentor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2052\u001b[0m                 bias=bias, training=training, momentum=momentum, eps=eps)\n\u001b[1;32m   2053\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2054\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m     return torch.batch_norm(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2035\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected more than 1 value per channel when training, got input size {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 512])"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for e in range(50):\n",
    "    \n",
    "    surface_points_augmented = PointcloudScaleAndTranslate(xyz1) # I do the augmentation\n",
    "    surface_points_augmented = surface_points_augmented.transpose(2, 1).contiguous()\n",
    "    \n",
    "    noise = 0.02 * torch.randn(1, 1024).cuda() #adding noise for creation of M and D matrix in the augmentator module\n",
    "    \n",
    "    sqn1 = sqn1.train()\n",
    "    augmentor = augmentor.train()\n",
    "    \n",
    "    optimizer_a.zero_grad()\n",
    "    optimizer1_sqn.zero_grad()\n",
    "    \n",
    "    aug_pc = augmentor(surface_points_augmented, noise) # obtaining the augmented point cloud\n",
    "    # SQN without augmentation\n",
    "    input_points1, input_neighbors1, input_pools1 = prepare_input(surface_points_augmented, k=16, num_layers=3, sub_sampling_ratio=4, \n",
    "                                                           device=DEVICE)\n",
    "    logits1, lat_feat1, query_feat1  = sqn1.forward(features1, input_points1, input_neighbors1, input_pools1, query1)\n",
    "    \n",
    "    #SQN with augmentation\n",
    "    input_points1_aug, input_neighbors1_aug, input_pools1_aug = prepare_input(surface_points_augmented, k=16, num_layers=3, sub_sampling_ratio=4, \n",
    "                                                           device=DEVICE)\n",
    "    logits1_aug, lat_feat_aug, query_feat_aug = sqn1.forward(features1, input_points1_aug, input_neighbors1_aug, input_pools1_aug, query1)\n",
    "    \n",
    "    augLoss  = aug_loss(logits1, logits1_aug, query_labels1, class_weights1)\n",
    "\n",
    "    clsLoss = cls_loss(logits1, logits1_aug, lat_feat1,\n",
    "                                lat_feat_aug)\n",
    "\n",
    "\n",
    "    augLoss.backward(retain_graph=True)\n",
    "    clsLoss.backward(retain_graph=True)\n",
    "\n",
    "    optimizer_c.step()\n",
    "    optimizer1_sqn.step()\n",
    "    \n",
    "    train_acc = eval_one_epoch(sqn1.eval(), trainDataLoader)\n",
    "    #test_acc = eval_one_epoch(sqn1.eval(), testDataLoader)\n",
    "\n",
    "    print('CLS Loss: {}'.format(round(clsLoss.data)))\n",
    "    print('AUG Loss: %.2f'%augLoss.data)\n",
    "\n",
    "    print('Train Accuracy: %f' % train_acc)\n",
    "    #self.log_string('Test Accuracy: %f'%test_acc)\n",
    "\n",
    "    #writer.add_scalar(\"Train_Acc\", train_acc, epoch)\n",
    "   # writer.add_scalar(\"Test_Acc\", test_acc, epoch)\n",
    "    \n",
    "    print(f\"Epoch {e+1}: {round(loss1.item(), 4)}\")\n",
    "    loss_list1.append(round(loss1.item(), 4))\n",
    "    \n",
    "plt.plot(epochs, loss_list1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
