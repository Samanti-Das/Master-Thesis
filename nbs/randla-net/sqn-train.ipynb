{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eeb6ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '/home/cem/Documents/imps/src')\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from imps.data import ScanNetScene, CLASS_NAMES\n",
    "from imps.sqn.model import SQN\n",
    "from imps.sqn.data_utils import prepare_input\n",
    "\n",
    "SCENE_DIR = '/home/cem/Documents/datasets/ScanNet/scans/scene0000_00'\n",
    "N_POINTS = int(1.5e5)\n",
    "# Not important we are not using this here yet. Keep this small for quick data processing\n",
    "RESOLUTION = 25\n",
    "SIGMAS = None\n",
    "LABEL_RATIO = 0.0001\n",
    "N_LABEL = int(N_POINTS*LABEL_RATIO)\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "IGNORED_LABELS = [0]\n",
    "\n",
    "def get_loss(logits, labels, class_weights):\n",
    "    class_weights = torch.from_numpy(class_weights).float().to(logits.device)\n",
    "    logits = logits.reshape(-1, len(class_weights))\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='none')\n",
    "    output_loss = criterion(logits, labels)\n",
    "    output_loss = output_loss.mean()\n",
    "    \n",
    "    return output_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdf85a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153587, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene.mesh.visual.face_colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a3de786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81369, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(mesh.vertices).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = o3d.geometry.TriangleMesh(vertices=o3d.utility.Vector3dVector(scene.mesh.vertices), \n",
    "                                 triangles=o3d.utility.Vector3iVector(scene.mesh.faces))\n",
    "mesh.vertex_colors = o3d.utility.Vector3dVector(scene.mesh.visual.vertex_colors[:, :-1] / 255)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = ScanNetScene(SCENE_DIR)\n",
    "\n",
    "voxel_grid, surface_points, surface_colors, vicinity_points, vicinity_distances, point_labels = scene.create_if_data(\n",
    "    RESOLUTION, N_POINTS, SIGMAS\n",
    ")\n",
    "\n",
    "class_counts = []\n",
    "for c in range(len(CLASS_NAMES.keys())):\n",
    "    class_counts.append(np.sum(point_labels == c))\n",
    "class_counts = np.array(class_counts)\n",
    "\n",
    "for ign in IGNORED_LABELS:\n",
    "    class_counts[ign] = 0\n",
    "class_weights = class_counts / class_counts.sum()\n",
    "\n",
    "query_idxs = np.random.choice(N_POINTS, N_LABEL, replace=False)\n",
    "query_points = surface_points[query_idxs]\n",
    "query_labels = point_labels[query_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255114b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.FloatTensor(surface_colors).unsqueeze(0).to(DEVICE)\n",
    "xyz = torch.FloatTensor(surface_points).unsqueeze(0)\n",
    "query = torch.FloatTensor(query_points).unsqueeze(0).to(DEVICE)\n",
    "query_labels = torch.LongTensor(query_labels).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "input_points, input_neighbors, input_pools = prepare_input(xyz, k=16, num_layers=3, sub_sampling_ratio=4, \n",
    "                                                           device=DEVICE)\n",
    "\n",
    "sqn = SQN(d_feature=3, d_in=8, encoder_dims=[8, 32, 64], decoder_dims=[64, len(CLASS_NAMES)], device=DEVICE)\n",
    "optimizer = optim.Adam(sqn.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ffaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sqn.train()\n",
    "\n",
    "for e in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    logits = sqn.forward(features, input_points, input_neighbors, input_pools, query)\n",
    "    loss = get_loss(logits, query_labels, class_weights)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {e+1}: {round(loss.item(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sqn.state_dict(), '../../data/sqn-0.0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea013119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d-env",
   "language": "python",
   "name": "3d-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
