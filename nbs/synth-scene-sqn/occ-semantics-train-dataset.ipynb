{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5912ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(1, '/home/cem/Documents/imps/src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imps.sqn.model import SQN\n",
    "from imps.sqn.data_utils import prepare_input\n",
    "from imps.metrics import compute_iou\n",
    "from imps.data.synth_scene import SynthSceneDataset, N_CLASS, CLASS_NAMES\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "DATA_ROOT = '/mnt/data.nas/shareddata/6G-futurelab/synthetic_room_dataset/rooms_04'\n",
    "POS_EMBEDDING = True\n",
    "LOGDIR = './logs'\n",
    "LOG = True\n",
    "\n",
    "# Classes taken from: https://github.com/autonomousvision/convolutional_occupancy_networks/blob/master/scripts/dataset_synthetic_room/build_dataset.py#L29\n",
    "# https://gist.github.com/tejaskhot/15ae62827d6e43b91a4b0c5c850c168e\n",
    "\n",
    "def get_occupancy_loss(logits, labels, pos_weight):\n",
    "    n_batch = logits.shape[0]\n",
    "    logits = logits.reshape(n_batch, -1)\n",
    "    labels = labels.reshape(n_batch, -1)\n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='none')\n",
    "    output_loss = criterion(logits, labels)\n",
    "    output_loss = output_loss.mean()\n",
    "    \n",
    "    return output_loss\n",
    "\n",
    "def get_semantic_loss(logits, labels, class_weights):\n",
    "    # is_occupied is 0 for free space so free space won't be included in the loss\n",
    "    # Walls are -1 and free space is > 4\n",
    "    \n",
    "    semantic_points = get_semantic_filter(labels)\n",
    "    # This selection flattens the batch\n",
    "    sem_logits = logits[semantic_points]\n",
    "    sem_labels = labels[semantic_points]\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='none')\n",
    "    output_loss = criterion(sem_logits, sem_labels)\n",
    "    output_loss = output_loss.mean()\n",
    "    \n",
    "    return output_loss\n",
    "\n",
    "def get_semantic_filter(labels):\n",
    "    return ~((labels == -1) | (labels > 4))\n",
    "\n",
    "def get_semantic_iou(logits, labels, n_class):\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    ious = []\n",
    "    \n",
    "    for c in range(n_class):\n",
    "        iou = jaccard_score((labels==c).astype(int), (preds==c).astype(int), pos_label=1)\n",
    "        ious.append(iou)\n",
    "        \n",
    "    return np.array(ious)\n",
    "\n",
    "def evaluate(sqn, eval_scene_data):\n",
    "    with torch.no_grad():\n",
    "        sqn.eval()\n",
    "\n",
    "        eval_query = eval_scene_data['query'][0].unsqueeze(0)\n",
    "        eval_occ_labels = eval_scene_data['query_occ'][0].unsqueeze(0)\n",
    "        eval_sem_labels = eval_scene_data['query_semantics'][0].unsqueeze(0)\n",
    "\n",
    "        occ_logits, sem_logits = sqn.forward(eval_scene_data['features'], eval_scene_data['input_points'], \n",
    "                                             eval_scene_data['input_neighbors'], eval_scene_data['input_pools'],\n",
    "                                             eval_query)\n",
    "\n",
    "        occ_pred = torch.nn.Sigmoid()(occ_logits).detach().cpu().numpy().squeeze()\n",
    "        occ_pred = (occ_pred > 0.5).astype(np.int)\n",
    "        occ_gold = eval_occ_labels.detach().cpu().numpy().squeeze()\n",
    "        occ_iou = jaccard_score(occ_gold, occ_pred)\n",
    "\n",
    "        semantic_filter = get_semantic_filter(eval_sem_labels)\n",
    "        sem_pred = sem_logits[semantic_filter].squeeze().detach().cpu().numpy()\n",
    "        sem_gold = eval_sem_labels[semantic_filter].squeeze().detach().cpu().numpy()\n",
    "\n",
    "        sem_iou = get_semantic_iou(sem_pred, sem_gold, N_CLASS)\n",
    "        existing_classes = (eval_scene_data['class_weights'] != 0).cpu().numpy()\n",
    "        sem_miou = sem_iou[existing_classes].mean()\n",
    "        \n",
    "    return occ_iou, sem_miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91507cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'test-rand'\n",
    "\n",
    "now = datetime.now()\n",
    "exp_name += f'-{int(now.timestamp())}'\n",
    "exp_dir = os.path.join(LOGDIR, exp_name)\n",
    "\n",
    "dataset = SynthSceneDataset(DATA_ROOT, DEVICE)\n",
    "eval_scene_data = dataset.get_scene_data(dataset.train_dirs[3], '00', iou_nums=['00', '01'], seed=31)\n",
    "\n",
    "sqn = SQN(d_feature=60, d_in=64, encoder_dims=[32, 64, 128], device=DEVICE, skip_connections=True, \n",
    "          second_head=5)\n",
    "optimizer = optim.Adam(sqn.parameters(), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=250, gamma=0.9)\n",
    "\n",
    "if LOG:\n",
    "    writer = SummaryWriter(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6b8af5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████▌                                                | 1648/10000 [2:34:01<13:00:36,  5.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8997/378057606.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscene_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scene_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'00'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_nums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'00'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     occ_logits, sem_logits  = sqn.forward(scene_data['features'], scene_data['input_points'], \n\u001b[0m\u001b[1;32m      8\u001b[0m                                           \u001b[0mscene_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_neighbors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_pools'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                           scene_data['query'])\n",
      "\u001b[0;32m~/Documents/imps/src/imps/sqn/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, xyz_points, xyz_neighbors, xyz_sub_samples, xyz_query)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_sub_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_query\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mf_encoder_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_sub_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_encoder_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/imps/src/imps/sqn/model.py\u001b[0m in \u001b[0;36mdecoder\u001b[0;34m(self, f_encoder_list, xyz_points, xyz_query)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_encoder_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mquery_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_encoder_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mlatent_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/imps/src/imps/sqn/model.py\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(self, xyz_query, f_encoder_list, xyz_points)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             interp = knn_interpolate(e_expand.reshape(-1, f_dim), p_expand.reshape(-1, 3), xyz_query.reshape(-1, 3), \n\u001b[0m\u001b[1;32m    195\u001b[0m                                      k=self.n_neighbor, batch_x=batch_x, batch_y=batch_y)\n\u001b[1;32m    196\u001b[0m             \u001b[0minterp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/3d-env/lib/python3.8/site-packages/torch_geometric/nn/unpool/knn_interpolate.py\u001b[0m in \u001b[0;36mknn_interpolate\u001b[0;34m(x, pos_x, pos_y, batch_x, batch_y, k, num_workers)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         assign_index = knn(pos_x, pos_y, k, batch_x=batch_x, batch_y=batch_y,\n\u001b[0m\u001b[1;32m     45\u001b[0m                            num_workers=num_workers)\n\u001b[1;32m     46\u001b[0m         \u001b[0my_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/3d-env/lib/python3.8/site-packages/torch_geometric/nn/pool/__init__.py\u001b[0m in \u001b[0;36mknn\u001b[0;34m(x, y, k, batch_x, batch_y, cosine, num_workers)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`knn` requires `torch-cluster`.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in tqdm(range(10000)):\n",
    "    sqn.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    scene_data = dataset.get_scene_data(dataset.train_dirs[3], '00', iou_nums=['00', '01'])\n",
    "    \n",
    "    occ_logits, sem_logits  = sqn.forward(scene_data['features'], scene_data['input_points'], \n",
    "                                          scene_data['input_neighbors'], scene_data['input_pools'], \n",
    "                                          scene_data['query'])\n",
    "\n",
    "    occ_loss = get_occupancy_loss(occ_logits, scene_data['query_occ'], scene_data['pos_w'])\n",
    "    sem_loss = get_semantic_loss(sem_logits, scene_data['query_semantics'], scene_data['class_weights'])\n",
    "        \n",
    "    loss = occ_loss + 0.1*sem_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if LOG:\n",
    "        writer.add_scalar('loss', occ_loss, e)\n",
    "        writer.add_scalar('sem-loss', sem_loss, e)\n",
    "    \n",
    "    if (e % 100) == 0:\n",
    "            train_occ_iou, train_sem_miou = evaluate(sqn, eval_scene_data)\n",
    "\n",
    "            if LOG:\n",
    "                writer.add_scalar('occ-iou', train_occ_iou, e)\n",
    "                writer.add_scalar('sem-miou', train_sem_miou, e)\n",
    "        \n",
    "    if scheduler.get_last_lr()[-1] > 2e-5:\n",
    "        scheduler.step()\n",
    "    \n",
    "    if LOG:\n",
    "        writer.add_scalar('lr', scheduler.get_last_lr()[-1], e)\n",
    "        torch.save(sqn.state_dict(), os.path.join(exp_dir, 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329fd716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqn.load_state_dict(torch.load('/mnt/data.nas/staff/eteke/sqn-single-experiments/occ-semantic-emb-skip-seed=31-lr=sch-1638545527/model'))\n",
    "# sqn.load_state_dict(torch.load('/mnt/data.nas/staff/eteke/sqn-single-experiments/occ-semantic-emb-skip-seed=31-lr=sch-q-batch-1638895595/model'))\n",
    "# eval_scene_data = dataset.get_scene_data(dataset.train_dirs[3], '00', ['03'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6aa01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d-env",
   "language": "python",
   "name": "3d-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
