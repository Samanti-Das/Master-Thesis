{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5912ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(1, '/home/cem/Documents/imps/src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "from imps.sqn.model import SQN\n",
    "from imps.sqn.data_utils import prepare_input\n",
    "from imps.metrics import compute_iou\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "DATA_ROOT = '/mnt/data.nas/shareddata/6G-futurelab/synthetic_room_dataset/rooms_04'\n",
    "scene = '00000004'\n",
    "POS_EMBEDDING = True\n",
    "LOGDIR = './logs'\n",
    "\n",
    "# Classes taken from: https://github.com/autonomousvision/convolutional_occupancy_networks/blob/master/scripts/dataset_synthetic_room/build_dataset.py#L29\n",
    "# https://gist.github.com/tejaskhot/15ae62827d6e43b91a4b0c5c850c168e\n",
    "\n",
    "CLASS_NAMES = OrderedDict({\n",
    "    -1: \"ground-plane\",\n",
    "    0: \"cabinet\",\n",
    "    1: \"chair\",\n",
    "    2: \"lamp\",\n",
    "    3: \"sofa\",\n",
    "    4: \"table\",\n",
    "    6: \"free-space\"\n",
    "})\n",
    "IGNORED_LABELS = (-1, 6)\n",
    "\n",
    "scene_dir = os.path.join(DATA_ROOT, scene)\n",
    "\n",
    "def get_loss(logits, labels, pos_weight):\n",
    "    n_batch = logits.shape[0]\n",
    "    logits = logits.reshape(n_batch, -1)\n",
    "    labels = labels.reshape(n_batch, -1)\n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='none')\n",
    "    output_loss = criterion(logits, labels)\n",
    "    output_loss = output_loss.mean()\n",
    "    \n",
    "    return output_loss\n",
    "\n",
    "def get_semantic_loss(logits, labels, class_weights):\n",
    "    # is_occupied is 0 for free space so free space won't be included in the loss\n",
    "    class_weights = torch.from_numpy(class_weights).float().to(logits.device)\n",
    "    logits = logits.reshape(-1, len(class_weights))\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='none')\n",
    "    output_loss = criterion(logits, labels)\n",
    "    output_loss = output_loss.mean()\n",
    "    \n",
    "    return output_loss\n",
    "\n",
    "def get_semantic_iou(logits, labels, n_class):\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    ious = []\n",
    "    \n",
    "    for c in range(n_class):\n",
    "        iou = jaccard_score((labels==c).astype(int), (preds==c).astype(int), pos_label=1)\n",
    "        ious.append(iou)\n",
    "        \n",
    "    return np.array(ious)\n",
    "\n",
    "def pos_embed(pos, L=10):\n",
    "    embs = []\n",
    "    \n",
    "    for l in range(L):\n",
    "        sin_emb = np.sin((2^l)*np.pi*pos)\n",
    "        cos_emb = np.cos((2^l)*np.pi*pos)\n",
    "        embs += [sin_emb, cos_emb]\n",
    "    \n",
    "    return np.concatenate(embs, axis=-1).astype(np.float)\n",
    "\n",
    "def get_data(scene_points, query_points, query_occ, embedding=False, seed=None):\n",
    "    \n",
    "    if embedding:\n",
    "        features = torch.FloatTensor(pos_embed(scene_points)).unsqueeze(0).to(DEVICE)\n",
    "    else:\n",
    "        features = torch.FloatTensor(scene_points).unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "    xyz = torch.FloatTensor(scene_points).unsqueeze(0)\n",
    "    \n",
    "    # This should be permutation invariant but it is not! WHY!!!\n",
    "    # Hypothesis: When we permute and sub-sample, during the kNN up-sampling part, the\n",
    "    # corresponding features will change.\n",
    "    # We have to permute the input since it is ordered wrt. to objects.\n",
    "    \n",
    "    if (seed is not None) and (seed != -1):\n",
    "        torch.manual_seed(seed)\n",
    "    elif seed == -1:\n",
    "        torch.manual_seed(31)\n",
    "    \n",
    "    point_perm = torch.randperm(xyz.size()[1])\n",
    "    xyz = xyz[:, point_perm]\n",
    "    features = features[:, point_perm]\n",
    "\n",
    "    query = torch.FloatTensor(query_points).unsqueeze(0).to(DEVICE)\n",
    "    query_labels = torch.FloatTensor(query_occ).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    input_points, input_neighbors, input_pools = prepare_input(xyz, k=8, num_layers=3, sub_sampling_ratio=4, \n",
    "                                                           device=DEVICE)\n",
    "    \n",
    "    return features, input_points, input_neighbors, input_pools, query, query_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91507cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'occ-semantic-emb-skip-seed=31-lr=sch'\n",
    "\n",
    "now = datetime.now()\n",
    "exp_name += f'-{int(now.timestamp())}'\n",
    "exp_dir = os.path.join(LOGDIR, exp_name)\n",
    "\n",
    "scene_pcd = o3d.io.read_point_cloud(os.path.join(scene_dir, 'pointcloud0.ply'));\n",
    "\n",
    "scene = np.load(os.path.join(scene_dir, 'pointcloud', 'pointcloud_00.npz'))\n",
    "query_iou = np.load(os.path.join(scene_dir, 'points_iou', 'points_iou_00.npz'))\n",
    "\n",
    "scene_points = scene['points']\n",
    "query_points = query_iou['points']\n",
    "query_occ = np.unpackbits(query_iou['occupancies'])\n",
    "query_semantics = query_iou['semantics']\n",
    "\n",
    "pos_w = np.sum(query_occ==0) / np.sum(query_occ==1)\n",
    "pos_w = torch.FloatTensor([pos_w]).to(DEVICE)\n",
    "\n",
    "class_counts = []\n",
    "N = 5\n",
    "for c in range(N):\n",
    "    class_counts.append(np.sum(query_semantics == c))\n",
    "class_counts = np.array(class_counts)\n",
    "class_weights = class_counts / class_counts.sum()\n",
    "\n",
    "sqn = SQN(d_feature=60, d_in=64, encoder_dims=[32, 64, 128], decoder_dims=[128, 32, 1], device=DEVICE,\n",
    "         skip_connections=True, second_head=5)\n",
    "optimizer = optim.Adam(sqn.parameters(), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=250, gamma=0.5)\n",
    "writer = SummaryWriter(exp_dir)\n",
    "\n",
    "features, input_points, input_neighbors, input_pools, query, query_labels = get_data(scene_points,\n",
    "                                                                                     query_points,\n",
    "                                                                                     query_occ,\n",
    "                                                                                     embedding=POS_EMBEDDING,\n",
    "                                                                                     seed=31)\n",
    "query_semantics = torch.LongTensor(query_semantics).unsqueeze(0).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8af5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer.add_mesh('pc', input_points[0])\n",
    "\n",
    "for e in tqdm(range(10000)):\n",
    "    sqn.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    occ_logits, sem_logits = sqn.forward(features, input_points, input_neighbors, input_pools, query)\n",
    "    occ_loss = get_loss(occ_logits, query_labels, pos_w)\n",
    "    \n",
    "    semantic_points = ~((query_semantics == -1) | (query_semantics == 6))\n",
    "    sem_logits = sem_logits[semantic_points]\n",
    "    sem_labels = query_semantics[semantic_points]\n",
    "    \n",
    "    sem_loss = get_semantic_loss(sem_logits, sem_labels, class_weights)\n",
    "    loss = occ_loss + 0.1*sem_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    writer.add_scalar('loss', occ_loss, e)\n",
    "    writer.add_scalar('sem-loss', sem_loss, e)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sqn.eval()\n",
    "        occ_logits, sem_logits = sqn.forward(features, input_points, input_neighbors, input_pools, query)\n",
    "        \n",
    "        occ_pred = occ_logits.detach().cpu().numpy().squeeze()\n",
    "        occ_pred = (occ_pred > 0.5).astype(np.int)\n",
    "        occ_gold = query_labels.detach().cpu().numpy().squeeze()\n",
    "        occ_iou = jaccard_score(occ_gold, occ_pred)\n",
    "        \n",
    "        sem_pred = sem_logits.squeeze().detach().cpu().numpy()\n",
    "        sem_gold = sem_labels.squeeze().detach().cpu().numpy()\n",
    "        \n",
    "        sem_iou = get_semantic_iou(sem_pred[semantic_points.squeeze().detach().cpu().numpy()], \n",
    "                                   sem_gold, len(class_weights))\n",
    "        sem_miou = sem_iou[class_weights != 0].mean()\n",
    "        \n",
    "        writer.add_scalar('occ-iou', occ_iou, e)\n",
    "        writer.add_scalar('sem-miou', sem_miou, e)\n",
    "        \n",
    "        for i in range(len(class_weights)):\n",
    "            writer.add_scalar(f'sem-{CLASS_NAMES[i]}-iou', sem_iou[i], e)\n",
    "        \n",
    "        if (e % 100) == 0:\n",
    "            writer.add_mesh('occ-pc', query[:, occ_pred == 1], global_step=e)\n",
    "    \n",
    "    if scheduler.get_last_lr()[-1] > 2e-5:\n",
    "        scheduler.step()\n",
    "    \n",
    "    writer.add_scalar('lr', scheduler.get_last_lr()[-1], e)\n",
    "    torch.save(sqn.state_dict(), os.path.join(exp_dir, 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(sqn.state_dict(), '../../data/sqn-occ-emb')\n",
    "sqn.load_state_dict(torch.load(os.path.join(exp_dir, 'model')));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, input_points, input_neighbors, input_pools, query, query_labels = get_data(scene_points,\n",
    "                                                                                     query_points,\n",
    "                                                                                     query_occ, \n",
    "                                                                                     embedding=POS_EMBEDDING,\n",
    "                                                                                     seed=31)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sqn.eval()\n",
    "    logits = sqn.forward(features, input_points, input_neighbors, input_pools, query)\n",
    "\n",
    "    pred = logits.detach().cpu().numpy().squeeze()\n",
    "    pred = (pred > 0.5).astype(np.int)\n",
    "    gold = query_labels.detach().cpu().numpy().squeeze()\n",
    "    \n",
    "    print(jaccard_score(gold, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_pts = query.cpu().squeeze().numpy()[pred == 1]\n",
    "print(len(occ_pts))\n",
    "\n",
    "occ_pcd = o3d.geometry.PointCloud()\n",
    "occ_pcd.points = o3d.utility.Vector3dVector(occ_pts)\n",
    "\n",
    "o3d.visualization.draw_geometries([occ_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(gold, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329fd716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d-env",
   "language": "python",
   "name": "3d-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
