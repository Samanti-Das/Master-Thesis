{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718cad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from collections import namedtuple\n",
    "\n",
    "sys.path.insert(1, '/home/cem/Documents/implicit_scene/LLFF')\n",
    "sys.path.insert(1, '/home/cem/Documents/implicit_scene/nerf_pl')\n",
    "sys.path.insert(1, '/home/cem/Desktop/ov-workspace/src')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imps.colmap import utils as colmap_utils\n",
    "from imps.colmap.run_colmap import run_automoatic_reconstructor\n",
    "from imps.nerf.data_utils import get_poses_bounds, generate_data\n",
    "from imps.nerf.model import get_embedder, get_single_nerf\n",
    "from imps.nerf.ray_utils import sample_points_on_ray\n",
    "from imps.nerf.render import render_hierarchical, render_single_model\n",
    "from imps.nerf.args import parser\n",
    "\n",
    "# Replicate the experiment arguments\n",
    "args = parser.parse_args([\"--exp_name\", \"no_fine\",\n",
    "                          \"--data_dir\", \"/home/cem/Desktop/ov-workspace/data/ov-v3\",\n",
    "                          \"--batch_size\", \"1024\",\n",
    "                          \"--down_scale\", \"4\",\n",
    "                          \"--colmap\"])\n",
    "LOG_FOLDER = '20210921-212831'\n",
    "embedding_include_input = True\n",
    "log_dir = os.path.join('../logs', args.exp_name, LOG_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b9dee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create models\n",
    "\n",
    "add_input = int(embedding_include_input) * 3\n",
    "\n",
    "pos_embedder = get_embedder(args.Lp, include_input=embedding_include_input)\n",
    "dir_embedder = get_embedder(args.Ld, include_input=embedding_include_input)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "coarse_nerf = tf.keras.models.load_model(os.path.join(log_dir, 'coarse'))\n",
    "fine_nerf = tf.keras.models.load_model(os.path.join(log_dir, 'fine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aabbc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "poses_bounds = get_poses_bounds(args.data_dir, args.colmap, args.near, args.far, args.img_format, \n",
    "                                args.img_prefix)\n",
    "\n",
    "image_files = sorted(glob.glob(os.path.join(args.data_dir, f'images/*{args.img_format}')))\n",
    "origins, viewdirs, imgs, bounds = generate_data(image_files, poses_bounds, down_scale=args.down_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8130dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first image chunk for test purposes\n",
    "h_start, h_end = 40, 80\n",
    "v_start, v_end = 50, 100\n",
    "\n",
    "origins_chunk = origins[5][h_start:h_end, v_start:v_end, :]\n",
    "viewdirs_chunk = viewdirs[5][h_start:h_end, v_start:v_end, :]\n",
    "imgs_chunk = imgs[5][h_start:h_end, v_start:v_end, :]\n",
    "bounds_chunk = bounds[5][h_start:h_end, v_start:v_end, :]\n",
    "\n",
    "original_shape = imgs_chunk.shape\n",
    "origins_chunk = tf.cast(origins_chunk.reshape(-1, 3), tf.float32)\n",
    "viewdirs_chunk = tf.cast(viewdirs_chunk.reshape(-1, 3), tf.float32)\n",
    "imgs_chunk = tf.cast(imgs_chunk.reshape(-1, 3), tf.float32)\n",
    "bounds_chunk = tf.cast(bounds_chunk.reshape(-1, 2), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(imgs[0])\n",
    "plt.imshow(imgs_chunk.numpy().reshape(*original_shape), aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_locs = sample_points_on_ray(bounds_chunk, args.N_coarse, perturb=False)\n",
    "coarse_pixel, coarse_density, coarse_weights, all_pixel, all_density, all_weights, all_locs = render_hierarchical(coarse_locs, coarse_nerf, fine_nerf, args.N_fine, pos_embedder,\n",
    "                                           dir_embedder, origins_chunk, viewdirs_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27561ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(all_pixel.numpy().reshape(*original_shape), aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78deef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = tf.reduce_sum(all_weights*all_density, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth.reshape(*original_shape[:2]), aspect='auto', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a1855",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_image = imgs[0]\n",
    "origins_eval = origins[0].reshape(-1, 3)\n",
    "viewdirs_eval = viewdirs[0].reshape(-1, 3)\n",
    "pixels_eval = imgs[0].reshape(-1, 3)\n",
    "bounds_eval = bounds[0].reshape(-1, 2)\n",
    "\n",
    "pred_image = np.zeros_like(pixels_eval)\n",
    "pred_depth = np.zeros((pixels_eval.shape[0], 1))\n",
    "test_batch_size = 2048\n",
    "\n",
    "for b in range(0, len(bounds_eval), test_batch_size):\n",
    "    origins_batch = tf.cast(origins_eval[b:b+test_batch_size], tf.float32)\n",
    "    directions_batch = tf.cast(viewdirs_eval[b:b+test_batch_size], tf.float32)\n",
    "    pixels_batch = tf.cast(pixels_eval[b:b+test_batch_size], tf.float32)\n",
    "    bounds_batch = tf.cast(bounds_eval[b:b+test_batch_size], tf.float32)\n",
    "\n",
    "    # Sample and perturb ray locations\n",
    "    coarse_locs = sample_points_on_ray(bounds_batch, args.N_coarse, perturb=False)\n",
    "    \n",
    "    _, _, _, fine_rgb, fine_density, fine_weights, _  = render_hierarchical(coarse_locs, coarse_nerf, \n",
    "                                                                            fine_nerf, args.N_fine,\n",
    "                                                                            pos_embedder, dir_embedder, \n",
    "                                                                            origins_batch, directions_batch)\n",
    "    pred_image[b:b+test_batch_size] = fine_rgb\n",
    "    pred_depth[b:b+test_batch_size] = tf.reduce_sum(fine_weights*fine_density, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_image.reshape(*imgs[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_depth.reshape(*imgs[0].shape[:2]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c93482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf-env",
   "language": "python",
   "name": "nerf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
